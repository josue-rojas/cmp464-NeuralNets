{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to write a Convolution Neural Network using Google Tensorflow\n",
    "\n",
    "# - Jamil G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Convolutional Neural Networks are extreamly similar to Neural Networks: they are made up of neurons (or tensors) that have learnable weights and biases. However this neural network assumes that input in an image. the Convolutional Layer is a three dimensional neuron that is used to help break apart the image into data (The MNIST dataset comprises 60,000 training examples and 10,000 test examples of the handwritten digits 0–9, formatted as 28x28-pixel monochrome images.)\n",
    "\n",
    "##### [This tutorial is assuming you have correctly installed Tensorflow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Import the following\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Our CNN will be in the following layout\n",
    "<p>\n",
    "<ol>\n",
    "<li>\n",
    "Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "    conv2d(): Constructs a two-dimensional convolutional layer. Takes number of filters, filter kernel size, padding, and activation function as arguments.\n",
    "</li>\n",
    "<li>\n",
    "Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "    max_pooling2d(): Constructs a two-dimensional pooling layer using the max-pooling algorithm. Takes pooling filter size and stride as arguments.\n",
    "</li>\n",
    "<li>\n",
    "Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
    "</li>\n",
    "<li>\n",
    "Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "</li>\n",
    "<li>\n",
    "Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "    dense(): Constructs a dense layer. Takes number of neurons and activation function as arguments.\n",
    "</li>\n",
    "<li>\n",
    "Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0–9).\n",
    "</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  #\n",
    "  # Our input layer is an image that looks as such\n",
    "  # [batch_size, image_width, image_height, channels],\n",
    "  # batch_size = how many images we are working with (-1 if you dont know the size)\n",
    "  # image_width = width of the image\n",
    "  # image_height = height of the image\n",
    "  # channels = number of color channels (since its a monochrome image it is only looking for black)\n",
    "  # for color images the channels can be 3 (red, green , blue)\n",
    "\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # in this first layer we will have 32 5 by 5 (800 filters)\n",
    "  # the activation function will be a RELU function\n",
    "  # the Padding argument determins what the output should look like (in our case the input and output should be the same)\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  \n",
    "  \n",
    "  # now we add the pooling layer\n",
    "  # pool size represents the pooling filters [width,height]\n",
    "  # strides represents the size of the stride\n",
    "  #\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "  \n",
    "  \n",
    "  # to preform classifications we are adding a dense layer (1024 neurons and RELu activation)\n",
    "  # but we need to flatten the inputs (to recreate the image)\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "  # 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 \n",
    "  # that any given element will be dropped during training)\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  # 10 neurons, one for each digit target class (0–9).\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      # For a given example, our predicted class is the element in the corresponding \n",
    "      # row of the logits tensor with the highest raw value. We can \n",
    "      # find the index of this element using the tf.argmax function:\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      # this will show us the probilitiy of the image to be a specific number\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "# Next, let's create an Estimator (a TensorFlow class for performing high-level \n",
    "# model training, evaluation, and inference) for our model. Add the following code to \n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model\\model.ckpt-2760\n",
      "INFO:tensorflow:Saving checkpoints for 2761 into C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00352161  0.00000128  0.06218408  0.00245948  0.00441723  0.00063659\n",
      "   0.90897059  0.01582474  0.00178042  0.00020396]\n",
      " [ 0.00649854  0.00004906  0.00003404  0.06764243  0.00714354  0.86202097\n",
      "   0.00543355  0.00003497  0.04397628  0.00716654]\n",
      " [ 0.00029208  0.00000566  0.00308422  0.00023561  0.91533256  0.00262638\n",
      "   0.04322397  0.00009438  0.00341631  0.03168885]\n",
      " [ 0.00020963  0.00122474  0.01705637  0.91199923  0.00006107  0.01483131\n",
      "   0.00026245  0.00029632  0.05361235  0.00044643]\n",
      " [ 0.00029202  0.93499959  0.01627621  0.00671535  0.00179467  0.00280622\n",
      "   0.00315454  0.0078731   0.01756785  0.00852038]\n",
      " [ 0.00052047  0.00960971  0.00189352  0.91876566  0.000251    0.02209142\n",
      "   0.00019054  0.01089966  0.03181222  0.00396586]\n",
      " [ 0.99850476  0.          0.00060019  0.00001004  0.00000011  0.00073045\n",
      "   0.0000391   0.00000176  0.00011143  0.0000022 ]\n",
      " [ 0.00000887  0.00000222  0.00003858  0.00001914  0.98464984  0.00182855\n",
      "   0.00832606  0.00010925  0.00226902  0.00274849]\n",
      " [ 0.99156392  0.00000003  0.00275054  0.0007468   0.0000025   0.00315689\n",
      "   0.0001717   0.00051457  0.00108693  0.00000631]\n",
      " [ 0.00768741  0.00004661  0.00809014  0.85430247  0.00005427  0.07584032\n",
      "   0.00011478  0.03068939  0.0207727   0.00240196]\n",
      " [ 0.00310606  0.00146185  0.96154004  0.01989029  0.0000201   0.00136751\n",
      "   0.00657304  0.00000023  0.00604015  0.00000083]\n",
      " [ 0.00921642  0.00499835  0.03379655  0.0155624   0.00204226  0.09764174\n",
      "   0.71429592  0.00027831  0.11766253  0.00450548]\n",
      " [ 0.00047746  0.00000838  0.00288275  0.00001246  0.96318239  0.00064485\n",
      "   0.00840614  0.00217892  0.01734118  0.0048655 ]\n",
      " [ 0.00008758  0.86978859  0.00854464  0.00502975  0.00396464  0.00507847\n",
      "   0.02367992  0.00231416  0.06813861  0.01337356]\n",
      " [ 0.00212335  0.00030346  0.00181421  0.00097116  0.01880307  0.0572808\n",
      "   0.00917419  0.00045196  0.89656699  0.01251086]\n",
      " [ 0.98249984  0.00001332  0.00369202  0.00245558  0.00006102  0.00433747\n",
      "   0.00532628  0.00001233  0.00127565  0.00032637]\n",
      " [ 0.00008934  0.00000478  0.00239652  0.00013271  0.97898203  0.00039743\n",
      "   0.00634895  0.00137499  0.00094379  0.00932955]\n",
      " [ 0.00090226  0.01432807  0.0019128   0.02347176  0.00228243  0.00454413\n",
      "   0.00014934  0.91441357  0.01848386  0.01951187]\n",
      " [ 0.10755131  0.00011698  0.6949411   0.12167729  0.00837597  0.0109757\n",
      "   0.00938882  0.00469481  0.03335556  0.00892245]\n",
      " [ 0.00083931  0.01448086  0.00549824  0.14757591  0.00166866  0.03042046\n",
      "   0.00039668  0.64924985  0.10343786  0.04643219]\n",
      " [ 0.00342253  0.00150999  0.00066883  0.00327294  0.01142377  0.00772432\n",
      "   0.00040112  0.834728    0.01118753  0.12566105]\n",
      " [ 0.00886977  0.000023    0.76505595  0.13910246  0.00000656  0.00683223\n",
      "   0.07859856  0.00000843  0.00149079  0.00001231]\n",
      " [ 0.89132643  0.00000179  0.00233124  0.01759334  0.00017314  0.03801005\n",
      "   0.03695773  0.00069693  0.01144742  0.00146184]\n",
      " [ 0.00312453  0.01261123  0.00751409  0.0090428   0.0024431   0.01575158\n",
      "   0.00308841  0.00322152  0.92530417  0.01789853]\n",
      " [ 0.09790892  0.00001088  0.00062902  0.04118735  0.00000304  0.81781554\n",
      "   0.00113442  0.00131527  0.03986353  0.00013204]\n",
      " [ 0.00321222  0.00126821  0.01310952  0.0008291   0.01514207  0.00226355\n",
      "   0.95619196  0.00009333  0.00545283  0.00243723]\n",
      " [ 0.03310502  0.00024651  0.0145949   0.040397    0.21121784  0.01503939\n",
      "   0.00180764  0.27313054  0.09040096  0.32006022]\n",
      " [ 0.00010194  0.98483616  0.00469606  0.004077    0.00023496  0.00031881\n",
      "   0.0007763   0.00096064  0.00315971  0.00083849]\n",
      " [ 0.0040051   0.00000774  0.979321    0.00123106  0.00006401  0.00414192\n",
      "   0.00460187  0.0000175   0.00650451  0.00010529]\n",
      " [ 0.02800927  0.00056573  0.00423046  0.02173658  0.00676214  0.03816679\n",
      "   0.00477923  0.42355639  0.02901246  0.44318101]\n",
      " [ 0.00774511  0.00047236  0.00052685  0.18345879  0.00111454  0.76369578\n",
      "   0.001023    0.00328979  0.01817869  0.02049498]\n",
      " [ 0.00281388  0.01736102  0.02006303  0.49619234  0.00347227  0.04998739\n",
      "   0.00221512  0.06335101  0.3290095   0.01553445]\n",
      " [ 0.00418202  0.05450352  0.007842    0.30942953  0.00202675  0.48266813\n",
      "   0.08747825  0.00736846  0.01821164  0.02628975]\n",
      " [ 0.00020944  0.97828114  0.0024285   0.00382818  0.00083283  0.00185915\n",
      "   0.00073783  0.00448062  0.00458953  0.00275267]\n",
      " [ 0.00661546  0.04100345  0.00893938  0.17696671  0.00309345  0.18153451\n",
      "   0.01456121  0.00042668  0.55941981  0.00743938]\n",
      " [ 0.00301224  0.13931845  0.03686511  0.01442588  0.0148647   0.02875316\n",
      "   0.031425    0.01127215  0.69560719  0.02445611]\n",
      " [ 0.00253966  0.00056834  0.01135913  0.6717782   0.00212311  0.2273434\n",
      "   0.00028887  0.00554205  0.07265455  0.00580271]\n",
      " [ 0.00793535  0.04042429  0.00350572  0.04855599  0.00687907  0.05384907\n",
      "   0.00076354  0.54235965  0.09380274  0.20192461]\n",
      " [ 0.22445689  0.00000172  0.75839031  0.00128613  0.00013258  0.00124184\n",
      "   0.00503994  0.00612396  0.00285585  0.00047085]\n",
      " [ 0.00133363  0.00065084  0.00051921  0.00196605  0.2424366   0.00423685\n",
      "   0.00467963  0.03028705  0.01955695  0.6943332 ]\n",
      " [ 0.00043201  0.00005046  0.9982565   0.00021825  0.00002478  0.00001541\n",
      "   0.00070729  0.00001106  0.00024847  0.00003574]\n",
      " [ 0.00077846  0.947016    0.00174547  0.01425669  0.00147903  0.00244376\n",
      "   0.00183076  0.00606258  0.02067892  0.00370825]\n",
      " [ 0.00113889  0.00001949  0.00237953  0.00007522  0.00060991  0.01217711\n",
      "   0.97775626  0.00000039  0.00579911  0.00004414]\n",
      " [ 0.0001651   0.13565923  0.00327242  0.02358164  0.19751602  0.00157519\n",
      "   0.00224541  0.23940894  0.05768285  0.33889318]\n",
      " [ 0.00030989  0.00250099  0.00203685  0.01875511  0.05995003  0.02432214\n",
      "   0.00143571  0.00550885  0.77135545  0.11382496]\n",
      " [ 0.00512189  0.0000569   0.91563123  0.06129236  0.00219698  0.00290311\n",
      "   0.00401591  0.00052437  0.00743082  0.00082638]\n",
      " [ 0.00639657  0.00023664  0.00404776  0.88104481  0.00246708  0.01579095\n",
      "   0.00062676  0.00258993  0.08166322  0.00513629]\n",
      " [ 0.00008341  0.00000023  0.00000062  0.00031161  0.00014118  0.00026609\n",
      "   0.00000069  0.99652195  0.00005305  0.00262125]\n",
      " [ 0.00024859  0.0000032   0.00014823  0.00003556  0.92883241  0.00075159\n",
      "   0.00167525  0.00104171  0.00216209  0.06510121]\n",
      " [ 0.00011593  0.00133837  0.0003493   0.00212026  0.90442014  0.00207907\n",
      "   0.01464565  0.00134101  0.01008842  0.06350194]\n",
      " [ 0.12157615  0.00000452  0.00799867  0.00484239  0.31723458  0.03591966\n",
      "   0.05472127  0.02473995  0.04981203  0.38315085]\n",
      " [ 0.00142003  0.04927836  0.01367946  0.00187072  0.73013121  0.01847117\n",
      "   0.13112788  0.00336863  0.02432612  0.02632637]\n",
      " [ 0.00024513  0.00012082  0.00368869  0.0002669   0.00260688  0.00084708\n",
      "   0.98970896  0.00000415  0.00240409  0.00010727]\n",
      " [ 0.00339734  0.00000508  0.01500424  0.84130132  0.00000201  0.12707973\n",
      "   0.00747172  0.00023523  0.00538106  0.00012225]\n",
      " [ 0.00071717  0.00001457  0.00004312  0.02642467  0.0001847   0.00031059\n",
      "   0.00001136  0.95911109  0.00026231  0.01292044]\n",
      " [ 0.90298259  0.00000232  0.00315327  0.02184332  0.00139612  0.05985705\n",
      "   0.00154176  0.00074301  0.00798471  0.00049595]\n",
      " [ 0.03229415  0.00069024  0.01541606  0.86597526  0.00085473  0.04672933\n",
      "   0.03294967  0.00023409  0.00320786  0.00164849]\n",
      " [ 0.61514926  0.00001655  0.01076146  0.23093724  0.00001007  0.06634197\n",
      "   0.00124926  0.02554644  0.04976011  0.00022756]\n",
      " [ 0.00014353  0.97325993  0.00422075  0.00268965  0.00247023  0.00121274\n",
      "   0.00193615  0.00125958  0.01248498  0.00032259]\n",
      " [ 0.00001589  0.00000946  0.00000603  0.00055785  0.00012903  0.00019814\n",
      "   0.00000072  0.99547136  0.0005113   0.00310025]\n",
      " [ 0.00414556  0.00000532  0.00492703  0.97928804  0.00012707  0.00429914\n",
      "   0.00005174  0.00304685  0.00369482  0.00041432]\n",
      " [ 0.00095533  0.00011516  0.00391172  0.00328371  0.02311021  0.01536471\n",
      "   0.00281584  0.09666444  0.75886214  0.0949168 ]\n",
      " [ 0.01591809  0.00000004  0.14999507  0.00007934  0.00074124  0.00053251\n",
      "   0.83144408  0.00031217  0.00062128  0.00035613]\n",
      " [ 0.00377036  0.00000565  0.91556782  0.00003186  0.00088834  0.00012848\n",
      "   0.0784158   0.00000044  0.00115673  0.00003457]\n",
      " [ 0.00564971  0.00424447  0.02417857  0.00872784  0.05333351  0.08000685\n",
      "   0.02459503  0.00993905  0.71411633  0.0752087 ]\n",
      " [ 0.00631815  0.0055945   0.04879158  0.06626949  0.01443274  0.02293588\n",
      "   0.00215781  0.05478112  0.70910954  0.06960918]\n",
      " [ 0.03600847  0.14615375  0.02772986  0.09913602  0.00279762  0.1578164\n",
      "   0.03785872  0.02623492  0.38639197  0.07987232]\n",
      " [ 0.00084341  0.92059356  0.01523763  0.00841736  0.00286488  0.00340257\n",
      "   0.01371115  0.00373803  0.02571137  0.00548019]\n",
      " [ 0.00002958  0.00000003  0.99971634  0.00019205  0.00000077  0.00000243\n",
      "   0.00001468  0.00000231  0.0000419   0.00000006]\n",
      " [ 0.02888046  0.00117427  0.00165782  0.00071887  0.00493196  0.82901847\n",
      "   0.01067854  0.00355478  0.10621823  0.01316661]\n",
      " [ 0.00034047  0.00087983  0.0006445   0.00084424  0.00164083  0.0001725\n",
      "   0.00004478  0.97161883  0.00174232  0.0220717 ]\n",
      " [ 0.0002913   0.00052442  0.14649706  0.05053234  0.00413735  0.08609518\n",
      "   0.00276874  0.01177243  0.68279517  0.01458599]\n",
      " [ 0.00078155  0.00000297  0.01412107  0.00005954  0.00318189  0.00107854\n",
      "   0.97729164  0.00000413  0.00324634  0.00023244]\n",
      " [ 0.87557042  0.00012626  0.01832239  0.00942371  0.00030103  0.02875259\n",
      "   0.04412088  0.0007878   0.01701532  0.00557966]\n",
      " [ 0.00003179  0.00000049  0.00002869  0.00016165  0.97234738  0.0007248\n",
      "   0.00246755  0.00015169  0.00140547  0.02268047]\n",
      " [ 0.00039492  0.92833143  0.00885132  0.00786894  0.00055731  0.00464209\n",
      "   0.02518725  0.00175077  0.02026526  0.00215061]\n",
      " [ 0.00041112  0.02314202  0.92043704  0.03335403  0.00005654  0.00065216\n",
      "   0.00260286  0.00012857  0.01917009  0.00004551]\n",
      " [ 0.00000545  0.99465513  0.00042659  0.00020375  0.00162252  0.00000672\n",
      "   0.00005773  0.00016337  0.00223672  0.00062193]\n",
      " [ 0.00037504  0.95088935  0.01007264  0.00480769  0.00379847  0.00108776\n",
      "   0.00700419  0.00914094  0.00973164  0.00309217]\n",
      " [ 0.00058009  0.38804713  0.01035145  0.00398639  0.3171767   0.01239249\n",
      "   0.1358939   0.00469492  0.05084717  0.0760298 ]\n",
      " [ 0.00188243  0.00049077  0.00074573  0.15130553  0.0189255   0.03707412\n",
      "   0.00043469  0.58205235  0.01134539  0.19574353]\n",
      " [ 0.00029844  0.00001383  0.00000878  0.00250152  0.00010569  0.00069189\n",
      "   0.000001    0.97582257  0.0010184   0.0195378 ]\n",
      " [ 0.00825068  0.00053556  0.02890462  0.02028512  0.09764317  0.06715153\n",
      "   0.43124565  0.00350332  0.29570466  0.04677562]\n",
      " [ 0.00044239  0.00252733  0.00080069  0.02560941  0.11327296  0.02939047\n",
      "   0.00084467  0.00752181  0.03078642  0.78880388]\n",
      " [ 0.99979252  0.          0.00002765  0.00002535  0.          0.00014421\n",
      "   0.00000575  0.00000064  0.00000367  0.00000028]\n",
      " [ 0.0000359   0.00061841  0.00039066  0.00099988  0.91091853  0.0020868\n",
      "   0.00026611  0.00042393  0.02250812  0.06175166]\n",
      " [ 0.00022593  0.0000131   0.00317626  0.00003487  0.00016751  0.00046693\n",
      "   0.9956364   0.000001    0.00024495  0.00003309]\n",
      " [ 0.01385943  0.11295868  0.00349404  0.01096339  0.00850915  0.08823345\n",
      "   0.00673473  0.00353873  0.73267853  0.01902983]\n",
      " [ 0.00350964  0.00054946  0.00035048  0.00259311  0.00435892  0.01218816\n",
      "   0.00030451  0.82876462  0.0082264   0.13915466]\n",
      " [ 0.00001136  0.00002     0.00000214  0.00018308  0.00286853  0.00017507\n",
      "   0.00000292  0.976309    0.00094883  0.01947914]\n",
      " [ 0.31804585  0.00006257  0.17128988  0.01528276  0.10602045  0.0373144\n",
      "   0.23117335  0.02274185  0.04056694  0.05750183]\n",
      " [ 0.00457726  0.89419883  0.02318538  0.01472618  0.00554174  0.01403506\n",
      "   0.00469942  0.00070739  0.03555734  0.00277139]\n",
      " [ 0.00169645  0.93691242  0.01259312  0.01702493  0.00156474  0.00447395\n",
      "   0.00668162  0.00324805  0.01040897  0.00539581]\n",
      " [ 0.0000573   0.0000332   0.00000631  0.00018626  0.57797801  0.00056109\n",
      "   0.00006322  0.05794516  0.00436096  0.35880831]\n",
      " [ 0.00062583  0.00003697  0.00074959  0.87251735  0.00087972  0.11008242\n",
      "   0.00017405  0.00061105  0.0118203   0.00250275]\n",
      " [ 0.00028518  0.00000554  0.00073414  0.0004119   0.98597217  0.00026708\n",
      "   0.0008883   0.00524056  0.00063779  0.00555734]\n",
      " [ 0.00474127  0.00017326  0.01744837  0.66963196  0.00033338  0.22107431\n",
      "   0.00073064  0.03356693  0.04775768  0.00454229]\n",
      " [ 0.05535208  0.00105785  0.18169242  0.09862843  0.00085409  0.33039555\n",
      "   0.03515591  0.03657111  0.25923511  0.00105746]\n",
      " [ 0.00076137  0.00000099  0.99634969  0.00024138  0.0000133   0.00003585\n",
      "   0.00254039  0.00000034  0.00005635  0.00000038]\n",
      " [ 0.0025703   0.00017461  0.42379537  0.08323754  0.00596762  0.02711313\n",
      "   0.09267466  0.00005355  0.35572773  0.00868551]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.372004, step = 2761\n",
      "INFO:tensorflow:Saving checkpoints for 2780 into C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.444285.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x2911b16cc50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=20,\n",
    "      hooks=[logging_hook])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-19-16:17:37\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/JamilG-Lenovo/Desktop/Code/Python/TensorFlow/CNN MNIST/mnist_convnet_model\\model.ckpt-2780\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-16:17:50\n",
      "INFO:tensorflow:Saving dict for global step 2780: accuracy = 0.8919, global_step = 2780, loss = 0.417171\n"
     ]
    }
   ],
   "source": [
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Evaluation Results: {'accuracy': 0.8919, 'loss': 0.41717118, 'global_step': 2780}\n"
     ]
    }
   ],
   "source": [
    "  print(\"\\n\\n\\nEvaluation Results: \" + str(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to take the evaluated Data(pictures) and labels(number) and store them into a \n",
    "# Dictionary so we can easily access specified numbers\n",
    "position = 0\n",
    "dic = {}\n",
    "for item in eval_labels:\n",
    "    if item in dic.keys():\n",
    "        photos = dic[item]\n",
    "        photos.append(eval_data[position])\n",
    "    else:\n",
    "        photos = [eval_data[position]]\n",
    "    dic[item] = photos\n",
    "    position = position +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets create the ability to display images\n",
    "# We will display a random selection of a specified number\n",
    "def display_digit(num):\n",
    "    print(\"we are looking for:\" + str(num))\n",
    "    label = num\n",
    "    random_image = randint(0, len(dic[num]))\n",
    "    print(\"using the \" + str(random_image) + \" image in the list\")\n",
    "    image = dic[num][0].reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Now we have a dictionary where the key represents the guessed number\n",
    "# the item is a list of images\n",
    "print(sorted(dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# One image has 784 numbers (28 by 28)\n",
    "print(str(len(dic[4][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are looking for:7\n",
      "using the 874 image in the list\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2911ffab208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are looking for:7\n",
      "using the 1019 image in the list\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2911f6815f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.39607850462\n"
     ]
    }
   ],
   "source": [
    "# lets see how different the two images are\n",
    "print( str ( sum(dic[7][703]) - sum (dic[7][483])   ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this shows that the two images are similar, but not 100% the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
